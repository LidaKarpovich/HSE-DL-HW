{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "205e416e-fa11-433d-b001-598e78a90d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Toxic comment  \\\n",
      "0              почитай посты у этого автора, дебил.    \n",
      "1  мне жаль тебя, гандон, если для тебя оскорблен...   \n",
      "2               тебе в говне ходить нормально, урод?   \n",
      "3  блять, я согласен, что энергия от виэ на текущ...   \n",
      "4  я этим сраным ватсаппом никогда не пользовался...   \n",
      "\n",
      "                                      Polite comment  \n",
      "0  попробуйте почитать посты этого автора, может ...  \n",
      "1  извините, но мне вас очень жаль, если для вас ...  \n",
      "2  извини, но приятно бы тебе было ходить в грязном?  \n",
      "3  я согласен с вами, что энергия от виэ на текущ...  \n",
      "4  просто я, к сожалению, ватсаппом никогда не по...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "df = pd.read_excel(\"toxic_non_toxic.xls\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c61e227-c673-4a36-bdb8-17876cebe3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.columns = ['toxic', 'polite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c830684-83fa-4d0c-9261-32555ba50b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/lidakarpovich/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower().strip())\n",
    "\n",
    "src_sentences = [tokenize(t) for t in df['toxic']]\n",
    "tgt_sentences = [tokenize(p) for p in df['polite']]\n",
    "\n",
    "specials = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
    "src_vocab = build_vocab_from_iterator(src_sentences, specials=specials)\n",
    "tgt_vocab = build_vocab_from_iterator(tgt_sentences, specials=specials)\n",
    "\n",
    "src_vocab.set_default_index(src_vocab['<unk>'])\n",
    "tgt_vocab.set_default_index(tgt_vocab['<unk>'])\n",
    "\n",
    "def encode(tokens, vocab, eos=True):\n",
    "    ids = [vocab[token] for token in tokens]\n",
    "    return ids + [vocab['<eos>']] if eos else ids\n",
    "\n",
    "src_data = [torch.tensor(encode(s, src_vocab)) for s in src_sentences]\n",
    "tgt_data = [torch.tensor([tgt_vocab['<sos>']] + encode(t, tgt_vocab, eos=True)) for t in tgt_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c284b4b5-99b8-4857-88f4-33b2450a992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, src, tgt):\n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.src[idx], self.tgt[idx]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=src_vocab['<pad>'], batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=tgt_vocab['<pad>'], batch_first=True)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "src_data = [torch.tensor(encode(s, src_vocab)) for s in src_sentences]\n",
    "tgt_data = [torch.tensor([tgt_vocab['<sos>']] + encode(t, tgt_vocab)) for t in tgt_sentences]\n",
    "\n",
    "\n",
    "src_train, src_val, tgt_train, tgt_val = train_test_split(\n",
    "    src_data, tgt_data, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "train_data = ToxicDataset(src_train, tgt_train)\n",
    "val_data = ToxicDataset(src_val, tgt_val)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size=1, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "val_data_pairs = []\n",
    "\n",
    "for i in range(len(src_data)):\n",
    "    for val_tensor in src_val:\n",
    "        if torch.equal(src_data[i], val_tensor):\n",
    "            val_data_pairs.append((\n",
    "                \" \".join(src_sentences[i]),\n",
    "                \" \".join(tgt_sentences[i])\n",
    "            ))\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ba908e-21ac-462f-aa1a-ab35feaa1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim, attn_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, attn_dim)\n",
    "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return torch.softmax(attention, dim=1) \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, attention, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(enc_hid_dim + emb_dim, dec_hid_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(enc_hid_dim + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attn_weights = self.attention(hidden.squeeze(0), encoder_outputs)\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        output = output.squeeze(1)\n",
    "        context = context.squeeze(1)\n",
    "        embedded = embedded.squeeze(1)\n",
    "        output = self.fc_out(torch.cat((output, context, embedded), dim=1))\n",
    "        return output, hidden, cell, attn_weights\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        tgt_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "\n",
    "        input = tgt[:, 0]\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed745d5d-4aa4-45f8-a871-49582f195593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "def evaluate_bleu(model, data_pairs):\n",
    "    total_bleu = 0\n",
    "    for src_text, tgt_text in data_pairs:\n",
    "        pred_text = generate_polite(model, src_text)\n",
    "        reference = tokenize(tgt_text)\n",
    "        hypothesis = tokenize(pred_text)\n",
    "        bleu = sentence_bleu([reference], hypothesis, smoothing_function=smoothie)\n",
    "        total_bleu += bleu\n",
    "\n",
    "    avg_bleu = total_bleu / len(data_pairs)\n",
    "    return avg_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a38e8144-2899-472d-b4ea-00c6b6ab7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polite(model, src_sentence, max_len=30):\n",
    "    model.eval()\n",
    "    tokens = tokenize(src_sentence)\n",
    "    src_tensor = torch.tensor(encode(tokens, src_vocab), dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
    "\n",
    "    inputs = torch.tensor([tgt_vocab['<sos>']], dtype=torch.long).to(device)\n",
    "    outputs = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell, _ = model.decoder(inputs, hidden, cell, encoder_outputs)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        if pred_token == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        outputs.append(pred_token)\n",
    "        inputs = torch.tensor([pred_token], dtype=torch.long).to(device)\n",
    "\n",
    "    return \" \".join(tgt_vocab.lookup_tokens(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eeeca9a6-830f-4618-8e55-c32ae1f60ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.4757, BLEU: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 5.6094, BLEU: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 5.3246, BLEU: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 5.0372, BLEU: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 4.8509, BLEU: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 4.6168, BLEU: 0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 4.4174, BLEU: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 4.1433, BLEU: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████| 6/6 [00:01<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 3.9912, BLEU: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 3.7096, BLEU: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 3.5947, BLEU: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 3.3926, BLEU: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 3.1185, BLEU: 0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 2.9770, BLEU: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 2.7043, BLEU: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 2.3775, BLEU: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 2.1118, BLEU: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 1.9555, BLEU: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 1.7120, BLEU: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 1.5319, BLEU: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 1.2912, BLEU: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 1.2225, BLEU: 0.0531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 1.1598, BLEU: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.8729, BLEU: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.7528, BLEU: 0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.6992, BLEU: 0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.5262, BLEU: 0.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.4882, BLEU: 0.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.5114, BLEU: 0.0553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.4321, BLEU: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.3699, BLEU: 0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 0.3008, BLEU: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 0.2895, BLEU: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 0.2102, BLEU: 0.0561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 0.2192, BLEU: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 0.1716, BLEU: 0.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 0.1465, BLEU: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 0.1413, BLEU: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 0.1182, BLEU: 0.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.1149, BLEU: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 0.0998, BLEU: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 0.0933, BLEU: 0.0640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 0.1031, BLEU: 0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 0.0833, BLEU: 0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 0.0856, BLEU: 0.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 0.0648, BLEU: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 0.0745, BLEU: 0.0649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 0.0564, BLEU: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 0.0715, BLEU: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|███████████████████████████████████| 6/6 [00:01<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.0558, BLEU: 0.0597\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(tgt_vocab)\n",
    "EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ATTN_DIM = 256\n",
    "DROPOUT = 0.5\n",
    "CLIP = 1.0\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
    "enc = Encoder(INPUT_DIM, EMB_DIM, ENC_HID_DIM, DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, attn, DROPOUT)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "EPOCHS = 50\n",
    "teacher_forcing_ratio = 0.7\n",
    "best_bleu = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    val_bleu = evaluate_bleu(model, val_data_pairs)\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, BLEU: {val_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9244950-b365-41fa-8d97-ad2943b0e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final BLEU score on validation set: 0.0597\n"
     ]
    }
   ],
   "source": [
    "final_bleu = evaluate_bleu(model, val_data_pairs)\n",
    "print(f\"\\nFinal BLEU score on validation set: {final_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7925450c-9709-4734-9235-543e8b64f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 0.8038\n"
     ]
    }
   ],
   "source": [
    "sample_pairs = list(zip(df['toxic'], df['polite']))[:100]\n",
    "bleu_score = evaluate_bleu(model, sample_pairs)\n",
    "print(f\"Average BLEU score: {bleu_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
